{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though mathematical operations can be performed in regular Python the NumPy module is often faster and more convenient. Most of this revolves around n-dimensional array objects which store regular arrays of data of a specified type (usually, but not limited to, numeric types). Such arrays can be used in a similar way to lists: they contain an ordered sequence of values and can be used in loops etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np  # Load the NumPy module, assign it the name \"np\" for convienence\n",
    "\n",
    "l = [1,4,9,16,25] # A list\n",
    "a = np.array(l)   # An array built from a list\n",
    "\n",
    "print(l)\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, an important idea with NumPy arrays is that operations can be performed on the array as a whole, rather than looping though all the component elements. This means that a fast internal implementation can be used. Also, it results in syntax similar to matrix algebra, where each variable is an entire array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain Python : loops\n",
    "a = [1,2,3,4,5]\n",
    "b = []\n",
    "for x in a:\n",
    "    b.append(a*3)\n",
    "    \n",
    "# List comprehension    \n",
    "c = [x*x for x in a]    \n",
    "\n",
    "# Numpy whole-array operations\n",
    "a = np.array([1,2,3,4,5])\n",
    "b = 3 * a   # All elements multiplied by three\n",
    "c = a * a   # All elements squared\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An array will contain elements of the same data type. This data type is determined from the contents of the array when it is constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([2, 5, 1, 8, 0])\n",
    "z = np.array([3.14129, 2.71828, 1.41421])\n",
    "\n",
    "print(y.dtype)  # int - whole numbers\n",
    "print(z.dtype)  # float - fixed precision real numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type of an array may be specifically stated (i.e. forced), irrespective of its initial elements. Also, the data type may be converted (making a new array in the process) using `astype()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([2, 5, 1, 8, 0], float)  # Force float dtype\n",
    "x = z.astype(int)                     # Convert to ints\n",
    "\n",
    "print(y, y.dtype)\n",
    "print(z, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many common operations are applied in an element-wise manner, i.e. to each value individually, and operations can work between two arrays if they have compatible sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 2.0, 3.0])\n",
    "y = np.array([3.0, 4.0, 5.0])\n",
    "\n",
    "print(x + 2)    # Add 2 to all values\n",
    "print(y / 2)    # Divide all values by 2\n",
    "\n",
    "# Element-wise operations bewtween different arrays with compatible sizes\n",
    "print(x + y)   \n",
    "print(x * y)   \n",
    "print(x - y)\n",
    "print(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-dimensional arrays\n",
    "\n",
    "An array can have a number of different dimensions/axes, i.e. so that it can represent vectors, matrices tensors etc. For example a 2D array, with 'row' and 'column' axes could be created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[4,5,6]])  # Make 2D array from list of lists\n",
    "print(x)\n",
    "print(x.shape)                   # (2,3) - rows x columns\n",
    "print(x.size)                    # 6 - elements in total\n",
    "print(x.ndim)                    # 2 - two axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarly for a 3D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[[0,1], [2,3]],\n",
    "              [[4,5], [6,7]],\n",
    "              [[8,9], [10,11]]])\n",
    "print(y)\n",
    "print(y.shape)\n",
    "print(y.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of array axes can be fored to be larger than what is automatically suggested by the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([0,1,4,9], ndmin=2)  # Forces a 2D array with one row\n",
    "print(z)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations are generally applied in an element-wise manner even when an array has multiple axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x * 0.01)  # Element-wise operation on 2D array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array creation from differently sized sub-collections works, but gives a 1D array of Python objects, which may not be the expected result..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,1], [2,3,4], [5,6,7,8]])\n",
    "print(x, x.dtype)\n",
    "print(2 * x)       # Each list is multiplied by two, not the elements inside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are easily reshaped to change the number of rows, columns axes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,101)     # The NumPy equivalent of range()\n",
    "y = x.reshape(10,10)     # Same data as 10 rows x 10 columns (makes a new array)\n",
    "\n",
    "print(y)\n",
    "print(y.shape)\n",
    "print(x.size, y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "The shape of two arrays determines whether they are compatible for operations that combine their elements. As shown above, arrays are compatible if they are the same shape/size. However, they may aso be compatible if their last axes are the same size. Here a 1D array of size 2 (`y`) can be added to a 2D array of size 3 x 2 (`x`) because the 1D size matches the number of 2D columns, so the operation can be applied separately (\"broadcast\") to each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[2,3], [4,5], [6,7]])\n",
    "y = np.array([10,100])\n",
    "\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, if an operation is applied to arrays with incompatible shapes, an error is triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[2, 4, 6, 8, 10])\n",
    "y = np.array([1, 3, 5])\n",
    "\n",
    "print(x*y) # Incompatible shapes : last axis different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is sometimes possible to reshape arrays so they become compatible. In the next example an extra last axis, with size 1, is added to an otherwise incompatible array. When this is multiplied by the 1D array `x`, each column of `y` (only a single value) can be multiplied separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2, 4, 6, 8, 10])\n",
    "y = np.array([1, 3, 5])\n",
    "\n",
    "y = y[:,None]      # Add a new axis (size 1) : .reshape() could also be used here\n",
    "\n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "print(x*y) # Shapes now compatible : operation is spread along last axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filled arrays\n",
    "\n",
    "There are various functions to create particular kinds of filled arrays (e.g. all zeros), with a specified size/shape and a spefified data type for the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,3))           # 2 x 3 array full of 0.0\n",
    "b = np.ones((3,2), int)       # 3 x 2 array full of 1\n",
    "c = np.full(4, 7.0)           # array, length four, full of 7.0\n",
    "d = np.identity(3)            # 3 x 3 identity (1.0 on diagonal 0.0 elsewhere) \n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, arrays can be created containing regular ranges of numbers, using start, end and step specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1.2, 4.4, 0.2)  # From 1.2 to <4.4 in steps of 0.1\n",
    "y = np.linspace(1.2, 4.4, 5)  # From 1.2 to 4.4 in five even steps\n",
    "z = np.logspace(2, 7, 5, base=10) # From 100 (10^2) to 10 million (10^7) in 5 even log_10 steps\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array sub-selections\n",
    "\n",
    "There is an index and range (slicing) syntax of the form `start:limit:step`, i.e. similar to the system used with lists and strings etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10) ** 2   # An array of sequential ints, squared\n",
    "print(x)\n",
    "print(x[2])         # number at index 2\n",
    "print(x[1:4])       # slice range (makes new array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranges may also have a third argument to specify the increment (step) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[2:9:2])   # Start at index 2, increment 2\n",
    "print(x[::2])     # Every other element (start:end is implicit)\n",
    "print(x[::-1])    # Negative increments means backwards (end:start implicit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexing and slicing syntax for arrays with more than one axis uses a comma, such as `data[i,j]` for a 2-dimensional array. This differs from regular Python where separate brackets are needed for each sub-list, e.g. using `data[i][j]`. Accessing with multiple brackets will still work with NumPy arrays, but will be slower, as it makes an intermediate array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(25).reshape(5,5)  # Two dimensional array : 5 rows x 5 columns\n",
    "print(y)\n",
    "print(y[2,3])     # One element specified with [Row, Column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-dimensional arrays, indices and slices/ranges may be specified for each axis to select sub-arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[1:4,1:4]) # A range of rows and columns (makes a new array)\n",
    "print(y[1,0:5])   # One entire row: all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entire axis ranges may be selected using `:`, but this is implicit for the last axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[-1])      # The entire last row: columns implicit\n",
    "print(y[-1,:])    # The entire last row, again \n",
    "print(y[:,2])     # One column (all rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuples of indices may be specified to make selections from an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (0,2,4)      # Row/column indices\n",
    "print(y[idx,:])    # Select specific rows, all columns\n",
    "print(y[idx, idx]) # Select row, column pairs : (0,0) (2,2) (4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical operations\n",
    "\n",
    "NumPy provides various mathematical functions, many of which are named like those in the standard Python `math` module. These operate on all the elements of an array, though they also work on single numbers. The functions will also accept regular iterable Python objects (lists or tuples etc.) as input, but a NumPy array is created where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(1,5)\n",
    "print(np.sqrt(x))   # Square root\n",
    "print(np.exp(x))    # E to the power\n",
    "print(np.log(x))    # Natural log\n",
    "print(np.mod(x, 2)) # Modular arithmetic : remainder in base 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [3.14129, 2.71828, 1.41421, -0.70717]\n",
    "print(np.abs(y))      # absolute/positive value\n",
    "print(np.round(y, 3)) # round to 3 d.p.\n",
    "print(np.ceil(y))     # whole number above (as float type)\n",
    "print(np.floor(y))    # whole number below (as float type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.radians([30.0, 60.0, 90.0, 135.0]) # Convert degrees to redians\n",
    "print(z)\n",
    "c = np.cos(z)        # Cosine \n",
    "print(c)\n",
    "print(np.arccos(c))  # Inverse cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inbuilt array methods\n",
    "\n",
    "There are various methods inbuilt into an array object, for example to calculate sums, extrema, mean and standard deviation. Without extra arguments these consider all elements of the array, irrespective of array shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[3,9], [3,1], [5,7]])\n",
    "\n",
    "print(x.min())          # minimum value (of all elements)\n",
    "print(x.max())          # maximum value\n",
    "print(x.sum())          # summation\n",
    "print(x.mean())         # mean\n",
    "print(x.std())          # standard devaiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods accept an `axis` specification so that the operation is performed multiple times along that array direction, thus generating a new array. It might be semantically confusing as to which axis number should be used to operate over rows or columns etc. For example, in a 2D array to get the summation for all rows you do `arr.sum(axis=1)`. The key idea here is that the sums are done over the column axis (`=1`) to give a value for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.max(axis=0))    # max along row axis : a value for each column\n",
    "print(x.sum(axis=1))    # sum along column axis : a value for each row\n",
    "print(x.mean(axis=1))   # mean along column axis : a value for each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean arrays and selection\n",
    "\n",
    "Comparison operations between arrays generate Boolean arrays giving `True` or `False` for each elemental comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 8, 9, 3])\n",
    "y = np.array([5, 0, 3, 7])\n",
    "z = x > y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element selections from arrays can be made by passing such arrays of `True` and `False` values (for each axis). This technique of using a 'mask' extends the index (row, column) based slection already shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(z)\n",
    "print(x[z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean masks can also be used to set a subset of array elements. For example here the negative values are set to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([3,-5,1,-2,-7,8,0])\n",
    "y = x.copy() # A copy of the original x\n",
    "z = x < 0    # Z has True for negative elements of x\n",
    "\n",
    "print(x)\n",
    "print(z)     # Boolean mask\n",
    "x[z] = 0     # Negative elements in x set to zero\n",
    "print(y)     # Original\n",
    "print(x)     # Modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating arrays\n",
    "\n",
    "* * \n",
    "\n",
    "### Mandelbrot example\n",
    "\n",
    "\n",
    "### Index selection methods\n",
    "\n",
    "Sometimes it is handy to convert from a Boolean array to indices, e.g. to know which (row, column) values are true. For this `nonzero()` can be used get a tuple representing the positions of the true (non-zero) elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = z.nonzero()        # Positions, for each axis, where z is true (x negative)\n",
    "print(idx)               # A tiple of arrays (one for each axis)\n",
    "print(y[idx])            # Values in y where z was true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar manner `argsort()` can be used to get the indices of an array in value order, which can then be used for sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([9,2,7,1,5,3,6,1])\n",
    "idx = y.argsort()  # An array of element positions, from smallest to largest value\n",
    "\n",
    "print(idx)\n",
    "print(y[idx])      # Values from y at sorted positions : makes a sorted array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also `argmax` and `argmin` can be used to get the index positions of extrema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = y.argmin()   #  Position of min value\n",
    "print(idx)\n",
    "print(y[idx])\n",
    "\n",
    "x = np.array([[1,7,2], [0,1,9]])\n",
    "idx = x.argmax(axis=1)  # The axis 1 (column) position for each row's max\n",
    "print(x)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear algebra\n",
    "\n",
    "There are many functions that relate to matrix operations and linear algebra, for example to calculate various products (inner, outer, cross), to transpose and find inverse matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(((1,1),(1,0)))\n",
    "y = np.array(((0,1),(1,1)))\n",
    "print(np.dot(x, y))               # dot product (=matrix multiplication for >1D)\n",
    "\n",
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(x.transpose())              # swap rows with cols)\n",
    "\n",
    "x = np.array(((1,1),(1,0)))\n",
    "print(np.linalg.inv(y))           # inverse transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy sub-modules\n",
    "\n",
    "NumPy has a number of handy submodules such as the very useful `random` module for pseudo-random number generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import uniform, normal # Import from sub-module\n",
    "\n",
    "# Sample uniform distribution\n",
    "a = uniform(0.0, 2.0, (5,5)) # From [0, 2), as 5 by 5 array\n",
    "print(a)\n",
    "\n",
    "# Sample normal distribution\n",
    "b = normal(0.0, 2.5, 10)  # Mean 0.0, SD 2.5, 10 values as flat array\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also the `fft` module for Fourier transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "l = 0.04\n",
    "w = 0.1\n",
    "t = np.arange(0.0, 30.0, 1.0)         # A range of time values\n",
    "x = np.exp(2j*pi*w*t) * np.exp(-l*t)  # Wave equation using complex numbers\n",
    "y = np.fft.fft(x)                     # Fast Fourier transform array of wave\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with matplotlib\n",
    "\n",
    "NumPy installations include the `matplotlib` module, which provides the ability to make graphs. For example, plotting the above using the `plot()` function makes a linegraph. The way this operates is that datsets are added individually before the completed plot is slown at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(x.real)  #  Real values from complex number\n",
    "plt.plot(x.imag)  #  Imaginary values\n",
    "plt.show()  #  Display on-screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is notable that invoking the `show()` funtion clears all of the plotted data,."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()  # No data plotted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many options for controling the presentation and style of the plots. A few examples are illustrated below to add an axis label, a figure legend and line style. For full options see the [matplotlib documentation](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot same data as before\n",
    "plt.plot(x.real, color='red', label='Real')\n",
    "plt.plot(x.imag, color='#0080FF', linewidth=5,\n",
    "         alpha=0.3, label='Imaginary')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.legend()  # Add legend : made with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as on-screen presentation, all the charts may be saved to a file using `savefig()` and specifying the save location. There are many file formats available including pixel formats such as PNG and JPEG and vector graphics such as PDF or SVG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file format is specified in the file name extension\n",
    "plt.savefig(\"TestGraph.png\", dpi=72)  # .png : PNG pixmap\n",
    "plt.savefig(\"TestGraph.pdf\", dpi=100) # .pdf : PDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several types of chart and graph are available. For example the `scatter()` function makes a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vals = 2000\n",
    "x_vals = np.arange(num_vals)\n",
    "norm_vals = np.random.normal(0.0, 1.0, num_vals) # Mean, STD, count\n",
    "plt.scatter(x_vals, norm_vals, s=4, alpha=0.5)  # size 4 spots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another handy plot uses `hist()` to make histogram of the data (this has many options from `numpy.histogram`). Here, we show a histogram of the same random, normally distributed data used above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with set number of bins in a set range\n",
    "plt.hist(norm_vals, bins=50, range=(-3.5, 3.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different graph types can be mixed together in the same plot if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(norm_vals, color='red')\n",
    "\n",
    "x = np.arange(-3.5, 3.6, 0.1)\n",
    "y = num_vals/4 * np.exp(-x*x/2)\n",
    "plt.plot(x, y, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-plots\n",
    "\n",
    "* *\n",
    "\n",
    "\n",
    "## SciPy\n",
    "\n",
    "SciPy is an extensive library that builds upon the NumPy arrays and their functions. It provides specialized scientific functionality for areas including further linear algebra, optimization, integration, interpolation, signal processing, image processing and differential equations. These are the modules listed at [scipy.org](https://docs.scipy.org):\n",
    "\n",
    "Subpackage |\tDescription\n",
    "-----------|----------\n",
    "cluster \t|Clustering algorithms\n",
    "constants \t|Physical and mathematical constants\n",
    "fftpack \t|Fast Fourier Transform routines\n",
    "integrate \t|Integration and ordinary differential equation solvers\n",
    "interpolate \t|Interpolation and smoothing splines\n",
    "io \t|Input and Output\n",
    "linalg \t|Linear algebra\n",
    "ndimage \t|N-dimensional image processing\n",
    "odr \t|Orthogonal distance regression\n",
    "optimize \t|Optimization and root-finding routines\n",
    "signal \t|Signal processing\n",
    "sparse \t|Sparse matrices and associated routines\n",
    "spatial \t|Spatial data structures and algorithms\n",
    "special \t|Special functions\n",
    "stats \t|Statistical distributions and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical distributions\n",
    "\n",
    "SciPy provides objects representing random variables for a variety of different statistical distributions. These are created by specifying the particular parameters for the distribution (e.g. mean and standard deviation for normal/Gaussian). Here normal and poisson distributions are illustrated. A random variable object is created by specifying the parameters for each distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, poisson\n",
    "\n",
    "# Make \"random variable\" objects with params\n",
    "norm_rv = norm(1.0, 0.5)   # (Mean, STD)\n",
    "pois_rv = poisson(1.5)     # (Event_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these objects we access the probability density function `.pdf()` for the (continuous) normal distribution and the probability mass function `.pmf()` for the Poisson distribution. These generate the probabilities of obtaining the input values (here `x`), according to the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 5, 0.1)  # Value to plot probs for\n",
    "\n",
    "# Get probabilites from the distributions\n",
    "y_norm = norm_rv.pdf(x)\n",
    "y_pois = pois_rv.pmf(x)  # Only works at discrete values\n",
    "\n",
    "# Make line plots\n",
    "plt.plot(x, y_norm, label='Normal')\n",
    "plt.plot(x, y_pois, label='Poisson') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random variable objects have many more associated methods. These are listed in detail in the [SciPy .stats documentation](https://docs.scipy.org/doc/scipy/reference/stats.html). Taking the normal distribution as an example we can calculate the cumulative density function with `.cdf()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative probability \n",
    "plt.plot(x, norm_rv.cdf(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also notable that the random variable's module often has a `.fit()` method to estimate statistical parameters from data. Here, for example, we use `norm` (without parenthesis and specific parameters) to estimate mean and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [-0.516, -0.486, 0.495, -0.07, 0.974,\n",
    "     1.27, 1.179, 0.458, 0.815, 1.163]\n",
    "\n",
    "mean, std = norm.fit(y)\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example uses the random variable objects in a different way, wrapping them in a function to perform a tailed-test, as would be done to estimate a p-value: the probability of obtaining a value (or more extreme) from a given random distribution with stated parameters. \n",
    "\n",
    "The function `normal_tail_test()` performs the test on an input array of numbers for a normal distribution with given mean value, `mv` and standard deviation `std`. There is an option to state if we want to do a one- or two-tailed test, i.e. consider only values on the same side of the mean or both sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_tail_test(values, mv, std, one_sided=True):\n",
    "  \n",
    "    norm_rv = norm(mv, std)     # Normal distrib. object\n",
    "    diffs = abs(values-mv)      # Separations from mean\n",
    "    integ = norm_rv.cdf(mv-diffs)  # Cumulative density function\n",
    "  \n",
    "    if not one_sided:   # Two-tailed test\n",
    "        integ *= 2      # Symmetric: double area\n",
    "\n",
    "    return integ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function can be tested given some parameters and test values. In this case the values could represent the heights of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean    = 1.76\n",
    "std_dev = 0.075\n",
    "values  = np.array([1.8, 1.9, 2.0])\n",
    "\n",
    "result = normal_tail_test(values, mean, std_dev, one_sided=True)\n",
    "print('Normal one-tail p-vals:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting\n",
    "\n",
    "While there are modules to do specialised fitting for statistical distributions, as shown above, SciPy has more general numerical fitting/optimization rutines that can be used with arbitrary functions. We can illustrate this using an example that trys to fit a scaled bimodal gaussian distribution. Out test data is constructed from randomly sampling two different normal distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.concatenate([np.random.normal(0.0, 1.0, 10000),\n",
    "                       np.random.normal(1.5, 0.5, 5000)])\n",
    "\n",
    "y_vals, x_edges = np.histogram(test, bins=100, range=(-4.0, 4.0))\n",
    "half_width = 4.0/100.0\n",
    "x_vals = x_edges[:-1] + half_width\n",
    "plt.plot(x_vals, y_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit this we first create a function `bimodal_norm()` which maps data to the probability density curve for a bimodal distribution using specified parameters. Here the parameters will be the amplitudes, means and standerd deviations for the two underlying, component curves. Internally this function simply uses `norm.pdf()` twice and adds the scaled result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Bimodal scaled normal distributions\n",
    "def bimodal_norm(data,mu1,sigma1,amp1,\n",
    "                      mu2,sigma2,amp2):\n",
    "\n",
    "    v1 = amp1 * norm.pdf(data, mu1, sigma1)\n",
    "    v2 = amp2 * norm.pdf(data, mu2, sigma2)\n",
    "    return v1 + v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then let SciPy fit our test data using this function via `.curve_fit()`, and vire the best-fit parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "params, cov = curve_fit(bimodal_norm, x_vals, y_vals)\n",
    "print(params[:3])\n",
    "print(params[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the fitted parameters to visualise the optimised bimodal and component curves in relation to the initial input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1,sigma1,amp1,mu2,sigma2,amp2 = params\n",
    "\n",
    "# Optimized bimodal\n",
    "d0 = bimodal_norm(x_vals, mu1,sigma1,amp1,mu2,sigma2,amp2)\n",
    "# Separate normal distribs\n",
    "d1 = amp1 * norm.pdf(x_vals, mu1, sigma1)\n",
    "d2 = amp2 * norm.pdf(x_vals, mu2, sigma2)\n",
    "\n",
    "plt.plot(x_vals, d0)\n",
    "plt.plot(x_vals, d1)\n",
    "plt.plot(x_vals, d2)\n",
    "plt.scatter(x_vals, y_vals, alpha=0.5) # Orginal data\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image data\n",
    "\n",
    "Below a simple example is given, showing the ndimage sub-module which is useful for reading and writing image pixel data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread\n",
    "\n",
    "img_file = 'examples/my_image.png'\n",
    "pixmap = imread(img_file)     # Read image data as array\n",
    "\n",
    "height, width, channels = pixmap.shape           \n",
    "red_channel   = pixmap[:,:,0]         # Color channels are last axis\n",
    "green_channel = pixmap[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle component analysis with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function illustrates the use of the NumPy module and performs a principle component analysis: treating input data as vectors it finds the orthogonal directions in the data of maximal variance (the Eigenvectors of the covariance matrix). This is often used on high-dimensionality data to create simpler representations that still preserve the most important features. The function takes two arguments, the input data, which assumed to be equivalent to a list of vectors, and the number of principle components to extract. There is a small complication in this function as linalg.eig() outputs a matrix (p_comp_mat below) where each Eigenvector is a column, rather than a row. This orientation is useful for applying the matrix as a transformation, as we demonstrate below. Though, in the code it means the matrix is sorted and selected on its last axis (using [:,:n] etc.). Also, this is why the transpose, pcomps.T is used when extracting the two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_principle_components(data, n=2):\n",
    "\n",
    "  data = np.array(data)               # Convert input to array\n",
    "\n",
    "  mean = data.mean(axis=0)            # Mean vector\n",
    "  centred_data = (data - mean).T      # Centre all vectors and transpose\n",
    "\n",
    "  covar = np.cov(centred_data)        # Get covariance matrix\n",
    "  evals, evecs = np.linalg.eig(covar) # Get Eigenvalues and Eigenvectors\n",
    "\n",
    "  indices = evals.argsort()[::-1]     # E. value indices by decreasing size\n",
    "\n",
    "  evecs = evecs[:,indices]            # Sort Eigenvecs according to Eigenvals\n",
    "  \n",
    "  p_comp_mat = evecs[:,:n]            # Select required principle components\n",
    "\n",
    "  return p_comp_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is tested using some random 3D data. Here the random module from NumPy is used to create three clusters of vector points. Initially each has the same mean (0.0) and standard deviation (0.5), but the last two clusters are transposed by adding an offset vector. The clusters are concatenated together (along the long axis) to create the final test dataset with three ‘blobs’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (100, 3)                     # 100 points times 3 dimensions\n",
    "d1 = random.normal(0.0, 0.5, size) \n",
    "d2 = random.normal(0.0, 0.5, size) + array([4.0, 1.0, 2.0])\n",
    "d3 = random.normal(0.0, 0.5, size) + array([2.0, 0.0, -1.0])\n",
    "test_data = concatenate([d1, d2, d3], axis=0)\n",
    "\n",
    "pcomps = get_principle_components (test_data, n=2)   # Run PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principle components are given back as a matrix, albeit in transposed form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1, pc2 = pcomps.T   # Extract the two PC vectors from columns\n",
    "\n",
    "for x, y, z in (pc1, pc2):\n",
    "  x *= 10             # Scale value so it can be seen better on graph       \n",
    "  y *= 10\n",
    "  pyplot.plot((0, x), (0, y))  # Plot PC x, y as line from origin (0,0)\n",
    "\n",
    "x, y, x = test_data.T          # Extract x and y vals from transpose\n",
    "\n",
    "pyplot.scatter(x, y, s=20, c='#0080FF', marker='o', alpha=0.5)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principle component matrix can be used to transform the test data. Here the first two principle components are used as new X and Y axis directions, illustrating that the transformation gives a better separated 2D view of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = dot(test_data, pcomps)\n",
    "\n",
    "x, y = transformed.T\n",
    "pyplot.scatter(x, y, s=20, c='#FF0000', marker='^')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
